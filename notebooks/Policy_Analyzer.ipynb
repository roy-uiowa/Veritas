{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64fd4f78-28c7-47e4-aa1f-348991e50a7a",
   "metadata": {},
   "source": [
    "# Veritas \n",
    "**Company Policy Analyzer**\n",
    "\n",
    "The Vertias is a **Policy Analyzer Chatbot**, uncovers the true meaning and intent behind policy language. Veritas is based on vector store retriever, that utilizes a vector store to fetch policy documents from X company and llm to create context aware ansewers based on the user query.  This retriever leverages the search methods implemented by the vector store, such as similarity search and Maximum Marginal Relevance (MMR), to query texts stored within it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2b8c70-860e-4c21-8bb2-3397ff37f442",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edccb0db-c2c4-4456-a2ad-32556520bfe3",
   "metadata": {},
   "source": [
    "For this project,I used the following libraries:\n",
    "\n",
    "*   [`ibm-watson-ai`](https://ibm.github.io/watsonx-ai-python-sdk/index.html) for using LLMs from IBM's watsonx.ai.\n",
    "*   [`langchain`, `langchain-ibm`, `langchain-community`](https://www.langchain.com/) for using relevant features from LangChain.\n",
    "*   [`pypdf`](https://pypi.org/project/pypdf/)is an open-source pure Python PDF library capable of splitting, merging, cropping, and transforming the pages of PDF files.\n",
    "*   [`chromadb`](https://www.trychroma.com/) is an open-source vector database used to store embeddings.\n",
    "*   [`lark`](https://pypi.org/project/lark/) is a general-purpose parsing library for Python. It is necessary for a Self-Querying Retriever.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17ddeb56-b012-4f0f-8ed8-22c6cd168c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed ibm-cos-sdk-2.13.6 ibm-cos-sdk-core-2.13.6 ibm-cos-sdk-s3transfer-2.13.6 ibm-watsonx-ai-1.1.2 jmespath-1.0.1 lomond-0.3.3 numpy-1.26.4 pandas-2.1.4 requests-2.32.2 tabulate-0.9.0 tzdata-2025.2\n",
      "Successfully installed langchain-0.2.1 langchain-core-0.2.43 langchain-text-splitters-0.2.4 langsmith-0.1.147 orjson-3.11.3 requests-toolbelt-1.0.0 tenacity-8.5.0\n",
      "Successfully installed langchain-ibm-0.1.11\n",
      "Successfully installed dataclasses-json-0.6.7 langchain-community-0.2.1 marshmallow-3.26.1 mypy-extensions-1.1.0 typing-inspect-0.9.0\n",
      "Successfully installed asgiref-3.9.2 backoff-2.2.1 bcrypt-5.0.0 build-1.3.0 cachetools-5.5.2 chroma-hnswlib-0.7.3 chromadb-0.4.24 click-8.3.0 coloredlogs-15.0.1 durationpy-0.10 fastapi-0.118.0 filelock-3.19.1 flatbuffers-25.9.23 fsspec-2025.9.0 google-auth-2.40.3 googleapis-common-protos-1.70.0 grpcio-1.75.1 hf-xet-1.1.10 httptools-0.6.4 huggingface-hub-0.35.3 humanfriendly-10.0 kubernetes-33.1.0 markdown-it-py-4.0.0 mdurl-0.1.2 mmh3-5.2.0 mpmath-1.3.0 onnxruntime-1.23.0 opentelemetry-api-1.37.0 opentelemetry-exporter-otlp-proto-common-1.37.0 opentelemetry-exporter-otlp-proto-grpc-1.37.0 opentelemetry-instrumentation-0.58b0 opentelemetry-instrumentation-asgi-0.58b0 opentelemetry-instrumentation-fastapi-0.58b0 opentelemetry-proto-1.37.0 opentelemetry-sdk-1.37.0 opentelemetry-semantic-conventions-0.58b0 opentelemetry-util-http-0.58b0 posthog-6.7.6 protobuf-6.32.1 pulsar-client-3.8.0 pyasn1-0.6.1 pyasn1-modules-0.4.2 pypika-0.48.9 pyproject_hooks-1.2.0 python-dotenv-1.1.1 requests-oauthlib-2.0.0 rich-14.1.0 rsa-4.9.1 shellingham-1.5.4 starlette-0.48.0 sympy-1.14.0 tokenizers-0.22.1 typer-0.19.2 uvicorn-0.37.0 uvloop-0.21.0 watchfiles-1.1.0 websockets-15.0.1 wrapt-1.17.3\n",
      "Successfully installed pypdf-4.3.1\n",
      "Successfully installed lark-1.1.9\n",
      "Successfully installed posthog-5.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install \"ibm-watsonx-ai==1.1.2\" | tail -n 1\n",
    "!pip install \"langchain==0.2.1\" | tail -n 1\n",
    "!pip install \"langchain-ibm==0.1.11\" | tail -n 1\n",
    "!pip install \"langchain-community==0.2.1\" | tail -n 1\n",
    "!pip install \"chromadb==0.4.24\" | tail -n 1\n",
    "!pip install \"pypdf==4.3.1\" | tail -n 1\n",
    "!pip install \"lark==1.1.9\" | tail -n 1\n",
    "!pip install 'posthog<6.0.0' | tail -n 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b5bfde-f72f-4b92-9e68-4d4e30bb8214",
   "metadata": {},
   "source": [
    "## Defining helper functions\n",
    "\n",
    "Use the following code to define some helper functions to reduce the repeat work in the notebook:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86cd518e-32d0-45e8-9e9f-04433ef9518a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use this section to suppress warnings generated by your code:\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abb9dd6-75e1-4a62-8ffe-986338c29058",
   "metadata": {},
   "source": [
    "## Creating a retriever model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38ee115-6ed8-4ccf-ab69-4017c55a4127",
   "metadata": {},
   "source": [
    "The following steps are involved  to create a retriever model using LangChain:\n",
    "\n",
    "- Building LLMs\n",
    "  \n",
    "- Splitting documents into chunks\n",
    "  \n",
    "- Building an embedding model\n",
    "  \n",
    "- Retrieving related knowledge from text\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4182f4-7ff9-4aad-b570-617e7637e0a1",
   "metadata": {},
   "source": [
    "### Build the LLM\n",
    "Develop or select a pre-trained language model that can understand and generate human-like text. This model serves as the foundation for processing and interpreting language data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ec4ce8e-17c1-4602-956e-eea134b65d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watsonx_ai.foundation_models import ModelInference\n",
    "from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams\n",
    "from ibm_watsonx_ai import Credentials\n",
    "from ibm_watsonx_ai.foundation_models.extensions.langchain import WatsonxLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1614206-d552-4e3d-a138-692f68d76dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm():\n",
    "    model_id = 'mistralai/mistral-small-3-1-24b-instruct-2503'\n",
    "    \n",
    "    parameters = {\n",
    "        GenParams.MAX_NEW_TOKENS: 256,  # this controls the maximum number of tokens in the generated output\n",
    "        GenParams.TEMPERATURE: 0.5, # this randomness or creativity of the model's responses\n",
    "    }\n",
    "    \n",
    "    credentials = {\n",
    "        \"url\": \"https://us-south.ml.cloud.ibm.com\"\n",
    "    }\n",
    "    \n",
    "    \n",
    "    project_id = \"skills-network\"\n",
    "    \n",
    "    model = ModelInference(\n",
    "        model_id=model_id,\n",
    "        params=parameters,\n",
    "        credentials=credentials,\n",
    "        project_id=project_id\n",
    "    )\n",
    "    \n",
    "    mixtral_llm = WatsonxLLM(model = model)\n",
    "    return mixtral_llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0a45dd-7f75-4ebb-8096-01e6b7474e01",
   "metadata": {},
   "source": [
    "### Create the embedding model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2cf0c7-c938-4304-88fc-033dff97922f",
   "metadata": {},
   "source": [
    "Create or utilize an embedding model to convert chunks of text into numerical vectors. These vectors represent the semantic meaning of the text, enabling the model to compare and retrieve relevant information based on similarity.\n",
    "The following code demonstrates how to build an embedding model using the `watsonx.ai` package.\n",
    "\n",
    "For this project, the `ibm/slate-125m-english-rtrvr` embedding model is used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e13964b7-3dd8-4e9c-a9f1-1aef21d998bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watsonx_ai.metanames import EmbedTextParamsMetaNames\n",
    "from langchain_ibm import WatsonxEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9d01955-31b4-41dc-b6de-6188170d4a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def watsonx_embedding():\n",
    "    embed_params = {\n",
    "        EmbedTextParamsMetaNames.TRUNCATE_INPUT_TOKENS: 3,\n",
    "        EmbedTextParamsMetaNames.RETURN_OPTIONS: {\"input_text\": True},\n",
    "    }\n",
    "    \n",
    "    watsonx_embedding = WatsonxEmbeddings(\n",
    "        model_id=\"ibm/slate-125m-english-rtrvr\",\n",
    "        url=\"https://us-south.ml.cloud.ibm.com\",\n",
    "        project_id=\"skills-network\",\n",
    "        params=embed_params,\n",
    "    )\n",
    "    return watsonx_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75387017-8f27-407a-bb8f-3509362e8049",
   "metadata": {},
   "source": [
    "#### Load Policy Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625614bc-44af-403e-9ba9-ab0946e7baa6",
   "metadata": {},
   "source": [
    "Before working on the policy analyzer, we need to load some company policy document in text. A `companypolicies.txt` dataset is given in the data directory.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e6932b-0fba-412a-9b09-21b171ba67fd",
   "metadata": {},
   "source": [
    "I am using `TextLoader` from `langchain_comunity` to load the document.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862d1c35-d71c-4ac9-b30f-e2f0dc257f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489539d5-d1bd-4b26-9689-a736b98308ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader(\"../data/companypolicies.txt\")\n",
    "txt_data = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708a2370-6fbf-4c44-aaf0-5076ebc16c14",
   "metadata": {},
   "source": [
    "Split `txt_data` into chunks. `chunk_size = 200`, `chunk_overlap = 20` has been set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0dfd2ba0-d4d5-4198-8d88-497979d5ac2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_txt = text_splitter(txt_data, 200, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af594bb5-83d5-40e8-ac87-99407f9ddd6d",
   "metadata": {},
   "source": [
    "Store the embeddings into a `ChromaDB`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c751b3-37fd-4cb7-858d-9d49bcd3fd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae7c9c77-0bee-4b5b-acd0-286a3d064fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(chunks_txt, watsonx_embedding())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8bc6af-7a7e-4381-8de3-7ae3d2d1e139",
   "metadata": {},
   "source": [
    "##### Simple similarity search\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf8f750-0e38-48c5-9867-e79901115cf2",
   "metadata": {},
   "source": [
    "Here is an example of a simple similarity search based on the vector database.\n",
    "\n",
    "For this demonstration, the query has been set to \"email policy\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1be366b-8442-4886-bccc-49ae677d66f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"email policy\"\n",
    "retriever = vectordb.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30e8c030-e9e9-44b9-8efc-89c00b1bef75",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c2bf14-009c-430e-9e66-2c81775cc2b8",
   "metadata": {},
   "source": [
    "By default, the number of retrieval results is four, and they are ranked by similarity level. I am specifing `search kwargs` like `k` to limit the retrieval results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9b059119-d692-4eba-a864-c61c2847efac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'companypolicies.txt'}, page_content='This policy serves as a framework for handling discipline and termination. The organization recognizes the importance of fairness and consistency in these processes, and decisions will be made after')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 1})\n",
    "docs = retriever.invoke(query)\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3cb2a4-d04b-4a85-a8df-b000e9ef46ad",
   "metadata": {},
   "source": [
    "##### MMR search\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5ac5c9-fc11-4097-8e3f-8ecae0b9ebdc",
   "metadata": {},
   "source": [
    "MMR in vector stores is a technique used to balance the relevance and diversity of retrieved results. It selects documents that are both highly relevant to the query and minimally similar to previously selected documents. This approach helps to avoid redundancy and ensures a more comprehensive coverage of different aspects of the query.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970af3e6-251f-45eb-8824-cc5988e88972",
   "metadata": {},
   "source": [
    "The following code is showing how to conduct an MMR search in a vector database. We just need to sepecify `search_type=\"mmr\"`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7946aead-4857-4fd2-beff-784a755a8866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'companypolicies.txt'}, page_content='This policy serves as a framework for handling discipline and termination. The organization recognizes the importance of fairness and consistency in these processes, and decisions will be made after'),\n",
       " Document(metadata={'source': 'companypolicies.txt'}, page_content='Employee Referrals: We encourage and appreciate employee referrals as they contribute to building a strong and engaged team.'),\n",
       " Document(metadata={'source': 'companypolicies.txt'}, page_content='any potential violations of this code and support the investigation of such matters.'),\n",
       " Document(metadata={'source': 'companypolicies.txt'}, page_content='Smoking Restrictions: Smoking inside company buildings, offices, meeting rooms, and other enclosed spaces is strictly prohibited. This includes electronic cigarettes and vaping devices.')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vectordb.as_retriever(search_type=\"mmr\")\n",
    "docs = retriever.invoke(query)\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d86f5b-c14a-44f6-a846-dc65f85b3f4f",
   "metadata": {},
   "source": [
    "##### Similarity score threshold retrieval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4eb905d-adf0-47d6-ae00-5ec3699d046c",
   "metadata": {},
   "source": [
    "We can also set a retrieval method that defines a similarity score threshold, returning only documents with a score above that threshold.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82c17908-c992-4287-ac30-aaaf9aef5479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'companypolicies.txt'}, page_content='This policy serves as a framework for handling discipline and termination. The organization recognizes the importance of fairness and consistency in these processes, and decisions will be made after'),\n",
       " Document(metadata={'source': 'companypolicies.txt'}, page_content='This policy aims to maintain a safe, healthy, and productive workplace.')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vectordb.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\", search_kwargs={\"score_threshold\": 0.4}\n",
    ")\n",
    "docs = retriever.invoke(query)\n",
    "docs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
